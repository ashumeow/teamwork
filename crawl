#!/usr/bin/env python

import os
import json

from config import configer
from crawler.query.query import Query
from crawler.query.builder import Builder
from crawler.crawler import Crawler
from db.driver import Driver

MEMBERS_PATH = os.path.join(os.path.dirname(__file__), './raw/members.json')
MEMBERS_FILE = os.path.abspath(MEMBERS_PATH)

INFO_PATH = os.path.join(os.path.dirname(__file__), './raw/info.json')
INFO_FILE = os.path.abspath(INFO_PATH)


def collect_github_data(config):
    crawler = Crawler(config['organization'].lower())

    crawler.add_members()
    crawler.add_info()


def collect_bigquery_data(config, driver):
    query = Query(config)
    builder = Builder(config['organization'].lower())

    result = query.execute(builder.build())

    if (result == [] or result is None):
        pass
    else:
        driver.insert('raw', result)


def filter_bigquery_data(driver):
    with open(MEMBERS_FILE, 'r') as f:
        members = json.loads(f.read())
        f.close()

    driver.filter_rows(members)


def main():
    config = configer.config('teamwork')
    query_config = configer.config('bigquery')

    driver = Driver(config)
    driver.connect()

    collect_github_data(config)
    collect_bigquery_data(query_config, driver)
    filter_bigquery_data(driver)

    driver.disconnect()


if __name__ == "__main__":
    main()
